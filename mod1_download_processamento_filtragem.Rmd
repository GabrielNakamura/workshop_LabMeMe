---
title: "Rotina download e processamento"
author: "Gabriel Nakamura"
date: "2025-03-19"
output: html_document
---

 
# Download of the databases that will be used 
  
Here you have to include your own databases. 
Here, just for an example, we will use standard PBDB and NOW databases 
Both databases are from their respective websites and are based on Carnivora records 


```{r}
# Needed functions

source(here::here("R_functions", "Lucas & Carlos - functions.R"))
```

## PBDB

```{r}
data_pbdb <- read_delim(here::here("PBDB_output","pbdb_cleaned.csv"), delim = ",", col_types = cols(.default = "?"),name_repair = "minimal")
```

## NOW

```{r}
data_now <- read.csv(here::here("NOW_output", "now_cleaned.csv"), h=T, sep = ",")
```


# Clean PBDB dataset 

```{r}
## Define the vector with the names of the columns to keep

selected_columns_pbdb = c("collection_no", "accepted_name", "max_ma", "min_ma", "family", "lng", "lat")  

filtered_data_pbdb = filter_columns(data_pbdb, selected_columns_pbdb)

## Display the first rows of the filtered dataset

head(filtered_data_pbdb)
```


# Clean NOW dataset 

```{r}
## Define the vector with the names of the columns to keep

selected_columns_now = c("LIDNUM", "SPECIES", "MAX_AGE", "MIN_AGE", "GENUS", "FAMILY", "LONG", "LAT")  

filtered_data_now = filter_columns(data_now, selected_columns_now)

## Display the first rows of the filtered dataset

head(filtered_data_now)
```


# Standardize column names between the two datasets

```{r}
## First, we should include the "_" between species name in the PBDB dataset 

filtered_data_pbdb

if ("accepted_name" %in% colnames(filtered_data_pbdb)) {
  filtered_data_pbdb$accepted_name = gsub(" ", "_", filtered_data_pbdb$accepted_name)
}

filtered_data_pbdb


## Then, we should merge the column names of the "SPECIES" and "GENUS" names in the NOW database

filtered_data_now

filtered_data_now = filtered_data_now %>%
  mutate(SPECIES_NAMES = paste(GENUS, SPECIES, sep = "_")) %>%
  dplyr::select(-GENUS, -SPECIES)  # Remove the original columns

head(filtered_data_now)



## Now we will change the column names to match between databases and to be compatible to the objects that will be created  

### PBDB

filtered_data_pbdb = filtered_data_pbdb %>%
  dplyr::rename("Site" = collection_no, 
                "Species" = accepted_name,
                "MaxT" = max_ma,
                "MinT" = min_ma,
                "Family" = family,
                "lng" = lng,
                "lat" = lat)  

filtered_data_pbdb = filtered_data_pbdb %>% # Adjust the position of columns
  dplyr::select(Species, MaxT, MinT, lng, lat, Site, Family)

filtered_data_pbdb = filtered_data_pbdb %>% # Remove lines that are not identified at family level 
  dplyr::filter(Family != "NO_FAMILY_SPECIFIED")


### NOW

filtered_data_now = filtered_data_now %>%
  dplyr::rename("Site" = LIDNUM , 
         "Species" = SPECIES_NAMES,
         "MaxT" = MAX_AGE,
         "MinT" = MIN_AGE,
         "Family" = FAMILY,
         "lng" = LONG,
         "lat" = LAT)  

filtered_data_now = filtered_data_now %>% # Adjust the position of columns
  dplyr::select(Species, MaxT, MinT, lng, lat, Site, Family)
```


# Clean and organize the data based on their temporal resolution

```{r}
# Dealing with occurrence resolution
# Looking at our data, we can see that it has much variation in time resolution 
# Resolution = the timespan between each occurrence for a species
# High variation could point to more uncertainty

pbdb = search.site(data = filtered_data_pbdb)
now = search.site(data = filtered_data_now)

# A little corrections for the sites in the NOW database:

now$Site=now$Site+max(pbdb$Site)
now$MaxT=as.numeric(now$MaxT)
now$MinT=as.numeric(now$MinT)

#########
# Use the function to clean datasets
#########

### PBDB
# Run the filter_resolution_and_plot function to PBDB dataset and using the temporal threshold of 5 Myr

pbdb_with_flags = filter_resolution_and_plot(pbdb, 5)

# Let's now create a new dataset removing the occurecences with flags (>= our threshold)

pbdb = pbdb_with_flags %>% filter(Resolution_flag == FALSE)


### NOW
# Run the filter_resolution_and_plot function to NOW dataset and using the temporal threshold of 5 Myr

now_with_flags = filter_resolution_and_plot(now, 5)

# Let's now create a new dataset removing the occurecences with flags (>= our threshold)

now = now_with_flags %>% filter(Resolution_flag == FALSE)


################
# Use the function to check the resolutions that were removed, how much time they differ from 
# the defined threshold 
################


### PBDB
# Create a plot to show the time difference (in Myr) between the removed occurence and the threshold 

excess_counts_table_pbdb <- plot_excess_resolution_and_counts(pbdb_with_flags, threshold = 5)

# Check the number of record within each category 

print(excess_counts_table_pbdb)


### NOW
# Create a plot to show the time difference (in Myr) between the removed occurence and the threshold 

excess_counts_table_now <- plot_excess_resolution_and_counts(now_with_flags, threshold = 5)

# Check the number of record within each category 

print(excess_counts_table_now)


################
# We can also see how many species, and who are they, based on the records with flags. 
# And we can organize them within the defined windows. 
################

### PBDB

species_table_excess_pbdb <- get_species_vectors_by_excess_interval (pbdb_with_flags, threshold = 5)
print(species_table_excess_pbdb)

### NOW

species_table_excess_now <- get_species_vectors_by_excess_interval (now_with_flags, threshold = 5)
print(species_table_excess_now)
```


# Select, based on the region, which database is going to be reduced due to pseudoreplicas

```{r}
# Standardizing region names

region <- tolower("North America")  # Convert to lowercase (e.g. "North America")

if (!is.null(region)) {
  if (region %in% c("na", "north america")) {
    chosen_df <- "NOW" #if user elects North America the PBDB is a better database
  } else if (region %in% c("eu", "ea", "eurasia", "europe")) {
    chosen_df <- "PBDB" #if user selects Eurasia the NOW is a better database
  } else {
    warning("Invalid region specified. Defaulting to NOW.")
    chosen_df <- "NOW" # Default
  }
} else {
  chosen_df <- "NOW"  # Default case
}

########################

PBDB_data = pbdb
NOW_data = now


PBDB_data <- PBDB_data %>%
  dplyr::mutate(across(c(MaxT, MinT, lng, lat), as.numeric))

NOW_data <- NOW_data %>%
  dplyr::mutate(across(c(MaxT, MinT, lng, lat), as.numeric))


# Finding pseudoreplicates function

PR <- find.pseudoreplicas(dtst1 = PBDB_data, dtst2 = NOW_data,
                          lat_threshold = 1, long_threshold = 1,
                          time_threshold = 6, print_progress = TRUE)

# Removing pseudoreplicates based on chosen dataset

if (chosen_df == "NOW") {
  NOW_no_pseudo <- remove.pseudoreplicas(PR, NOW_data)  
  true_occs <- rbind(PBDB_data, NOW_no_pseudo)
} else {  # chosen_df == "PBDB"
  PBDB_no_pseudo <- remove.pseudoreplicas(PR, PBDB_data)
  true_occs <- rbind(PBDB_no_pseudo, NOW_data)
}


# Check the final database 

print(true_occs)

Final_table=true_occs
```


# Indicate the continent in which each record was found

```{r}
##This can be used to leave the records of specific geographic regions. You only need to filter the new database regarding the geographic region we want. 


### continental information

NAm <- data.frame(lat=c(90,   90,  78.13,   57.5,  15,  15,  1.25,  1.25,  51,  60,    60, 90),
                  lon=c(-168.75 ,-10 ,-10     ,-37.5 ,-30 ,-75 ,-82.5 ,-105  ,-180 ,-180 ,-168.75, -168.75))
NAm2 <- data.frame(lat=c(51,   51,  60, 51),
                   lon=c(166.6, 180, 180, 166.6))
SAm <- data.frame(lat=c(1.25,   1.25,  15,  15, -60, -60, 1.25),
                  lon=c(-105, -82.5,  -75, -30, -30, -105, -105))
europe <- data.frame(lat=c(90,   90,  42.5, 42.5, 40.79, 41, 40.55, 40.40, 40.05, 39.17, 35.46,
                           33,   38,  35.42, 28.25, 15,  57.5,  78.13, 90),
                     lon=c(-10, 77.5, 48.8, 30,   28.81, 29, 27.31, 26.75, 26.36, 25.19, 27.91,
                           27.5, 10, -10,  -13,   -30, -37.5, -10, -10))
africa <- data.frame(lat=c(15,  28.25 ,35.42 ,38 ,33   ,31.74 ,29.54 ,27.78 ,11.3 ,12.5 ,-60 ,-60, 15),
                     lon=c(-30 ,-13   ,-10 ,10 ,27.5 ,34.58 ,34.92 ,34.46 ,44.3 ,52    ,75 ,-30, -30))
australia <- data.frame(lat=c(-11.88, -10.27, -10 ,-30    ,-52.5 ,-31.88, -11.88),
                        lon=c(110,      140  ,145 ,161.25 ,142.5  ,110, 110))
asia <- data.frame(lat=c(90   ,42.5 ,42.5 ,40.79 ,41 ,40.55 ,40.4  ,40.05 ,39.17 ,35.46 ,33   ,
                         31.74 ,29.54 ,27.78 ,11.3 ,12.5 ,-60 ,-60 ,-31.88 ,-11.88 ,-10.27 ,33.13 ,51    ,60  ,90, 90),
                   lon=c(77.5 ,48.8 ,30   ,28.81 ,29 ,27.31 ,26.75 ,26.36 ,25.19 ,27.91 ,27.5 ,
                         34.58 ,34.92 ,34.46 ,44.3 ,52   ,75  ,110  ,110   ,110    ,140    ,140   ,166.6 ,180 ,180, 77.5))
asia2 <- data.frame(lat=c(90    ,90      ,60      ,60, 90),
                    lon=c(-180 ,-168.75 ,-168.75 ,-180, -180))
antarctica <- data.frame(lat=c(-60, -60, -90, -90, -60),
                         lon=c(-180, 180, 180, -180, -180))

### continents dataframe

continents <- list(
  y=c(NAm$lat, NA, NAm2$lat, NA, SAm$lat, NA, europe$lat,NA,africa$lat,NA,
      australia$lat,NA,asia$lat,NA,asia2$lat,NA,antarctica$lat),
  x=c(NAm$lon, NA, NAm2$lon, NA, SAm$lon, NA,europe$lon,NA,africa$lon,NA,
      australia$lon,NA,asia$lon,NA,asia2$lon,NA,antarctica$lon),
  names=c("North America", "North America:2", "South America", "Europe",
          "Africa","Australia","Asia","Asia:2","Antarctica"))
class(continents) <- "map"

### assigning continents to our fossil data

points <- data.frame(Final_table$lng, Final_table$lat)
continents_of_each_record <- maps::map.where(continents, points)

### add a column at the end of the main dataframe with the continents

Final_table$continent <- continents_of_each_record
```


# We can check how our occurrences are distributed over the map

```{r}
# Load the world map
world_map <- map_data("world")

# Create the plot
occurrences_map =  
  ggplot() +
  geom_polygon(data = world_map, aes(x = long, y = lat, group = group), fill = "gray", color = "white") +
  geom_point(data = Final_table, aes(x = lng, y = lat), color = "red", size = 1) +
  geom_text(data = Final_table, aes(x = lng, y = lat, label = ""), vjust = -1, hjust = 0.5) +
  coord_fixed(1.3) +
  labs(title = "Geographic distribution of occurrences", x = "Longitude", y = "Latitude")

# Plot the map 
occurrences_map
```